{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Custom MiniGPT (Basic implementation)\n",
        "- [Dataset repo](https://www.kaggle.com/datasets)\n",
        "- [Dataset used --> Drake Lyrics](https://www.kaggle.com/datasets/juicobowley/drake-lyrics?select=drake_lyrics.txt)"
      ],
      "metadata": {
        "id": "QrbZAipr8JXq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LwpXOGJPeojl"
      },
      "outputs": [],
      "source": [
        "with open(\"sample_data/drake_lyrics.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaWwQhkPg-71",
        "outputId": "27220933-df2c-4570-a069-c404335b40c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "772371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvXoScIeoBNS",
        "outputId": "bd54d0e8-f5fa-4b43-9b53-4b47b0c08a18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"[Verse]\n",
            "Put my feelings on ice\n",
            "Always been a gem\n",
            "Certified lover boy, somehow still heartless\n",
            "Heart is only gettin' colder\"\n",
            "\"[Verse]\n",
            "Hands are tied\n",
            "Someone's in my ear from the other side\n",
            "Tellin' me that I should pay you no mind\n",
            "Wanted you to not be with me all night\n",
            "Wanted you to not stay with me all night\n",
            "I know, you know, who that person is to me\n",
            "Doesn't really change things\n",
            "\n",
            "[Chorus]\n",
            "I know you're scared of dating, falling for me\n",
            "Shorty, surely you know me\n",
            "Right here for you always\n",
            "You know, I don't ever change\n",
            "Right here for you always\n",
            "You know I don't ever change\n",
            "Right here for you\n",
            "\n",
            "[Bridge]\n",
            "In mind you make me want to do things, love you\n",
            "Like I'm supposed to\n",
            "You make me want to love you\n",
            "Like I'm supposed to\n",
            "You make me want to love you\n",
            "Like I'm supposed to, remind you\n",
            "Ayy\n",
            "\n",
            "[Chorus]\n",
            "I know you're scared of dating, falling for me\n",
            "Shorty, by now you know me\n",
            "Right here for you always\n",
            "You know, I don't ever change\n",
            "Right here for you always\n",
            "You know I don't ever change\n",
            "Right here for\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace('\"', '')\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhA-kpeCoGLR",
        "outputId": "9a0b3326-6751-4a70-961c-7f1c5267930d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Verse]\n",
            "Put my feelings on ice\n",
            "Always been a gem\n",
            "Certified lover boy, somehow still heartless\n",
            "Heart is only gettin' colder\n",
            "[Verse]\n",
            "Hands are tied\n",
            "Someone's in my ear from the other side\n",
            "Tellin' me that I should pay you no mind\n",
            "Wanted you to not be with me all night\n",
            "Wanted you to not stay with me all night\n",
            "I know, you know, who that person is to me\n",
            "Doesn't really change things\n",
            "\n",
            "[Chorus]\n",
            "I know you're scared of dating, falling for me\n",
            "Shorty, surely you know me\n",
            "Right here for you always\n",
            "You know, I don't ever change\n",
            "Right here for you always\n",
            "You know I don't ever change\n",
            "Right here for you\n",
            "\n",
            "[Bridge]\n",
            "In mind you make me want to do things, love you\n",
            "Like I'm supposed to\n",
            "You make me want to love you\n",
            "Like I'm supposed to\n",
            "You make me want to love you\n",
            "Like I'm supposed to, remind you\n",
            "Ayy\n",
            "\n",
            "[Chorus]\n",
            "I know you're scared of dating, falling for me\n",
            "Shorty, by now you know me\n",
            "Right here for you always\n",
            "You know, I don't ever change\n",
            "Right here for you always\n",
            "You know I don't ever change\n",
            "Right here for yo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfqUR1lXoYTn",
        "outputId": "ea04fdc8-7ca9-4019-956a-c832395c9bc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '\\x81', '\\x9d', '¡', '¦', '¨', '©', '«', '±', '³', 'º', 'Ã', 'â', 'œ', 'Ÿ', '˜', '“', '”', '…', '€', '™']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8_XeI9so2h9",
        "outputId": "c9a7e4d5-27fc-4b7a-ae31-d11ad07edf8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Very basic encoding / tokenization\n",
        "char_to_int = {char:i for i, char in enumerate(chars)}\n",
        "int_to_char = {i:char for i, char in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [char_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_char[i] for i in l])\n",
        "\n",
        "print(encode(\"Laying on the beach\"))\n",
        "print(len(encode(\"Laying on the beach\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfWyAdN6pMNd",
        "outputId": "2eb8ff68-9392-48e9-9747-b85553922c65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[39, 57, 81, 65, 70, 63, 1, 71, 70, 1, 76, 64, 61, 1, 58, 61, 57, 59, 64]\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode(\"Laying on the beach\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuItheQmsQcz",
        "outputId": "fd243460-d41c-45bf-9815-9da85f8832b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Laying on the beach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Dataset from Python to Pytorch"
      ],
      "metadata": {
        "id": "epxG8t_QvHef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "YyPEBJt2vNIu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text to tensor\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyf88Y6zvPQa",
        "outputId": "28e911ca-5c6d-4610-caff-c090708c7447"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([770671]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7eGboQTvRWi",
        "outputId": "590b2dcf-d26f-4fa7-b7d7-990b9f441895"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([54, 49, 61, 74, 75, 61, 55,  0, 43, 77, 76,  1, 69, 81,  1, 62, 61, 61,\n",
            "        68, 65, 70, 63, 75,  1, 71, 70,  1, 65, 59, 61,  0, 28, 68, 79, 57, 81,\n",
            "        75,  1, 58, 61, 61, 70,  1, 57,  1, 63, 61, 69,  0, 30, 61, 74, 76, 65,\n",
            "        62, 65, 61, 60,  1, 68, 71, 78, 61, 74,  1, 58, 71, 81, 11,  1, 75, 71,\n",
            "        69, 61, 64, 71, 79,  1, 75, 76, 65, 68, 68,  1, 64, 61, 57, 74, 76, 68,\n",
            "        61, 75, 75,  0, 35, 61, 57, 74, 76,  1, 65, 75,  1, 71, 70, 68, 81,  1,\n",
            "        63, 61, 76, 76, 65, 70,  6,  1, 59, 71, 68, 60, 61, 74,  0, 54, 49, 61,\n",
            "        74, 75, 61, 55,  0, 35, 57, 70, 60, 75,  1, 57, 74, 61,  1, 76, 65, 61,\n",
            "        60,  0, 46, 71, 69, 61, 71, 70, 61,  6, 75,  1, 65, 70,  1, 69, 81,  1,\n",
            "        61, 57, 74,  1, 62, 74, 71, 69,  1, 76, 64, 61,  1, 71, 76, 64, 61, 74,\n",
            "         1, 75, 65, 60, 61,  0, 47, 61, 68, 68, 65, 70,  6,  1, 69, 61,  1, 76,\n",
            "        64, 57, 76,  1, 36,  1, 75, 64, 71, 77, 68, 60,  1, 72, 57, 81,  1, 81,\n",
            "        71, 77,  1, 70, 71,  1, 69, 65, 70, 60,  0, 50, 57, 70, 76, 61, 60,  1,\n",
            "        81, 71, 77,  1, 76, 71,  1, 70, 71, 76,  1, 58, 61,  1, 79, 65, 76, 64,\n",
            "         1, 69, 61,  1, 57, 68, 68,  1, 70, 65, 63, 64, 76,  0, 50, 57, 70, 76,\n",
            "        61, 60,  1, 81, 71, 77,  1, 76, 71,  1, 70, 71, 76,  1, 75, 76, 57, 81,\n",
            "         1, 79, 65, 76, 64,  1, 69, 61,  1, 57, 68, 68,  1, 70, 65, 63, 64, 76,\n",
            "         0, 36,  1, 67, 70, 71, 79, 11,  1, 81, 71, 77,  1, 67, 70, 71, 79, 11,\n",
            "         1, 79, 64, 71,  1, 76, 64, 57, 76,  1, 72, 61, 74, 75, 71, 70,  1, 65,\n",
            "        75,  1, 76, 71,  1, 69, 61,  0, 31, 71, 61, 75, 70,  6, 76,  1, 74, 61,\n",
            "        57, 68, 68, 81,  1, 59, 64, 57, 70, 63, 61,  1, 76, 64, 65, 70, 63, 75,\n",
            "         0,  0, 54, 30, 64, 71, 74, 77, 75, 55,  0, 36,  1, 67, 70, 71, 79,  1,\n",
            "        81, 71, 77,  6, 74, 61,  1, 75, 59, 57, 74, 61, 60,  1, 71, 62,  1, 60,\n",
            "        57, 76, 65, 70, 63, 11,  1, 62, 57, 68, 68, 65, 70, 63,  1, 62, 71, 74,\n",
            "         1, 69, 61,  0, 46, 64, 71, 74, 76, 81, 11,  1, 75, 77, 74, 61, 68, 81,\n",
            "         1, 81, 71, 77,  1, 67, 70, 71, 79,  1, 69, 61,  0, 45, 65, 63, 64, 76,\n",
            "         1, 64, 61, 74, 61,  1, 62, 71, 74,  1, 81, 71, 77,  1, 57, 68, 79, 57,\n",
            "        81, 75,  0, 52, 71, 77,  1, 67, 70, 71, 79, 11,  1, 36,  1, 60, 71, 70,\n",
            "         6, 76,  1, 61, 78, 61, 74,  1, 59, 64, 57, 70, 63, 61,  0, 45, 65, 63,\n",
            "        64, 76,  1, 64, 61, 74, 61,  1, 62, 71, 74,  1, 81, 71, 77,  1, 57, 68,\n",
            "        79, 57, 81, 75,  0, 52, 71, 77,  1, 67, 70, 71, 79,  1, 36,  1, 60, 71,\n",
            "        70,  6, 76,  1, 61, 78, 61, 74,  1, 59, 64, 57, 70, 63, 61,  0, 45, 65,\n",
            "        63, 64, 76,  1, 64, 61, 74, 61,  1, 62, 71, 74,  1, 81, 71, 77,  0,  0,\n",
            "        54, 29, 74, 65, 60, 63, 61, 55,  0, 36, 70,  1, 69, 65, 70, 60,  1, 81,\n",
            "        71, 77,  1, 69, 57, 67, 61,  1, 69, 61,  1, 79, 57, 70, 76,  1, 76, 71,\n",
            "         1, 60, 71,  1, 76, 64, 65, 70, 63, 75, 11,  1, 68, 71, 78, 61,  1, 81,\n",
            "        71, 77,  0, 39, 65, 67, 61,  1, 36,  6, 69,  1, 75, 77, 72, 72, 71, 75,\n",
            "        61, 60,  1, 76, 71,  0, 52, 71, 77,  1, 69, 57, 67, 61,  1, 69, 61,  1,\n",
            "        79, 57, 70, 76,  1, 76, 71,  1, 68, 71, 78, 61,  1, 81, 71, 77,  0, 39,\n",
            "        65, 67, 61,  1, 36,  6, 69,  1, 75, 77, 72, 72, 71, 75, 61, 60,  1, 76,\n",
            "        71,  0, 52, 71, 77,  1, 69, 57, 67, 61,  1, 69, 61,  1, 79, 57, 70, 76,\n",
            "         1, 76, 71,  1, 68, 71, 78, 61,  1, 81, 71, 77,  0, 39, 65, 67, 61,  1,\n",
            "        36,  6, 69,  1, 75, 77, 72, 72, 71, 75, 61, 60,  1, 76, 71, 11,  1, 74,\n",
            "        61, 69, 65, 70, 60,  1, 81, 71, 77,  0, 28, 81, 81,  0,  0, 54, 30, 64,\n",
            "        71, 74, 77, 75, 55,  0, 36,  1, 67, 70, 71, 79,  1, 81, 71, 77,  6, 74,\n",
            "        61,  1, 75, 59, 57, 74, 61, 60,  1, 71, 62,  1, 60, 57, 76, 65, 70, 63,\n",
            "        11,  1, 62, 57, 68, 68, 65, 70, 63,  1, 62, 71, 74,  1, 69, 61,  0, 46,\n",
            "        64, 71, 74, 76, 81, 11,  1, 58, 81,  1, 70, 71, 79,  1, 81, 71, 77,  1,\n",
            "        67, 70, 71, 79,  1, 69, 61,  0, 45, 65, 63, 64, 76,  1, 64, 61, 74, 61,\n",
            "         1, 62, 71, 74,  1, 81, 71, 77,  1, 57, 68, 79, 57, 81, 75,  0, 52, 71,\n",
            "        77,  1, 67, 70, 71, 79, 11,  1, 36,  1, 60, 71, 70,  6, 76,  1, 61, 78,\n",
            "        61, 74,  1, 59, 64, 57, 70, 63, 61,  0, 45, 65, 63, 64, 76,  1, 64, 61,\n",
            "        74, 61,  1, 62, 71, 74,  1, 81, 71, 77,  1, 57, 68, 79, 57, 81, 75,  0,\n",
            "        52, 71, 77,  1, 67, 70, 71, 79,  1, 36,  1, 60, 71, 70,  6, 76,  1, 61,\n",
            "        78, 61, 74,  1, 59, 64, 57, 70, 63, 61,  0, 45, 65, 63, 64, 76,  1, 64,\n",
            "        61, 74, 61,  1, 62, 71, 74,  1, 81, 71])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.9 * len(data)) # 90% of data will be used for training\n",
        "train_data = data[:train_split]\n",
        "validation_data = data[train_split:] # 10% for validation data\n",
        "print(train_data.shape)\n",
        "print(validation_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhnI9f-uvvTg",
        "outputId": "eb988256-8190-4d5d-ae76-eb2f0905d65b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([693603])\n",
            "torch.Size([77068])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size + 1] # +1 for predicting next character"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tlpTRBjv9C2",
        "outputId": "d06edf5e-740b-45af-8fbc-4c6dc19c6415"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([54, 49, 61, 74, 75, 61, 55,  0, 43])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size] # input\n",
        "y = train_data[1:block_size + 1] # output --> start predicting after the input\n",
        "\n",
        "for i in range(block_size):\n",
        "  context = x[:i+1].numpy()\n",
        "  target = y[i] # i because we satart at position 1 instead of 0\n",
        "  print(f\"Input to the model: {context} the target should be {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8be8WSh_womp",
        "outputId": "3bd4478f-2a8d-42fc-ec60-289ab1d3490f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to the model: [54] the target should be 49\n",
            "Input to the model: [54 49] the target should be 61\n",
            "Input to the model: [54 49 61] the target should be 74\n",
            "Input to the model: [54 49 61 74] the target should be 75\n",
            "Input to the model: [54 49 61 74 75] the target should be 61\n",
            "Input to the model: [54 49 61 74 75 61] the target should be 55\n",
            "Input to the model: [54 49 61 74 75 61 55] the target should be 0\n",
            "Input to the model: [54 49 61 74 75 61 55  0] the target should be 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(block_size):\n",
        "  context = decode(x[:i+1].numpy())\n",
        "  target = decode([y[i].item()]) # i because we satart at position 1 instead of 0\n",
        "  print(f\"Input to the model: {context} the target should be {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdlO9PGoxbAX",
        "outputId": "2ecb7e49-5310-4310-ce0f-ffe84dbaa628"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to the model: [ the target should be V\n",
            "Input to the model: [V the target should be e\n",
            "Input to the model: [Ve the target should be r\n",
            "Input to the model: [Ver the target should be s\n",
            "Input to the model: [Vers the target should be e\n",
            "Input to the model: [Verse the target should be ]\n",
            "Input to the model: [Verse] the target should be \n",
            "\n",
            "Input to the model: [Verse]\n",
            " the target should be P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = block_size = 8\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "3M8IIDMO4Nyo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_data(dataset_split):\n",
        "  data = train_data if dataset_split == 'train' else validation_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "xOxyYuYi44_R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = get_batch_data('train')"
      ],
      "metadata": {
        "id": "Cq7f_DXN5lHc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_batch.shape, y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3Y5uYiy59-R",
        "outputId": "fd7cf488-b0dd-44c7-e01c-bc25c293e3ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 8]) torch.Size([8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7vqkXkT6H1F",
        "outputId": "210c099a-4d23-4f65-d0b8-9a117c7f22c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[30, 71, 69, 61,  1, 76, 64, 74],\n",
            "        [81,  1, 46, 71, 70, 63, 82, 55],\n",
            "        [76, 65, 70, 63,  1, 69, 71, 70],\n",
            "        [77, 61, 68, 29, 57, 70, 60,  1],\n",
            "        [ 1, 69, 61,  1, 68, 65, 67, 61],\n",
            "        [ 1, 65, 75, 11,  1, 81, 71, 77],\n",
            "        [ 1, 79, 61,  1, 63, 61, 76,  1],\n",
            "        [ 1, 70, 71, 79, 11,  1, 63, 65]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snoJuIkG6Ohy",
        "outputId": "52510f33-87fd-4af0-cfeb-2abe9a2a990f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[71, 69, 61,  1, 76, 64, 74, 71],\n",
            "        [ 1, 46, 71, 70, 63, 82, 55,  0],\n",
            "        [65, 70, 63,  1, 69, 71, 70, 61],\n",
            "        [61, 68, 29, 57, 70, 60,  1, 66],\n",
            "        [69, 61,  1, 68, 65, 67, 61,  1],\n",
            "        [65, 75, 11,  1, 81, 71, 77,  1],\n",
            "        [79, 61,  1, 63, 61, 76,  1, 81],\n",
            "        [70, 71, 79, 11,  1, 63, 65, 74]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "0V7g8nQ367-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VOR07fXZ6QQ0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tril(torch.ones(block_size, block_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9A6p2ae9Wcw",
        "outputId": "de87afed-1aa2-4638-9f85-f3ee93fcdf3e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, head_size, dropout=0.1):\n",
        "    super(AttentionHead, self).__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    # Inputs k, v, q --> refer to attention is all you need paper\n",
        "    self.key = nn.Linear(n_embeddings, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embeddings, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embeddings, head_size, bias=False)\n",
        "\n",
        "    # Triangular matrix for masking:\n",
        "    # the first input we attend to first elem, the second we attend to first and second elems and so on\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    key = self.key(x)\n",
        "    query = self.query(x)\n",
        "\n",
        "    attention_scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(query.size(-1))\n",
        "\n",
        "    # query.size(1) --> first dimension to get only the block_size; -inf for stability\n",
        "    attention_scores = attention_scores.masked_fill(self.tril[:query.size(1), :query.size(1)] == 0, float(\"-inf\"))\n",
        "    attention_scores = F.softmax(attention_scores, dim=-1) # along the last dimension\n",
        "    attention_scores = self.dropout(attention_scores)\n",
        "    value = self.value(x)\n",
        "    return torch.matmul(attention_scores, value), attention_scores"
      ],
      "metadata": {
        "id": "kS9pnwhm7NK-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  # n_head --> how many attention heads we want to create\n",
        "  def __init__(self, n_head, head_size, dropout=0.1):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_head)])\n",
        "    self.projection = nn.Linear(n_embeddings, n_embeddings)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Concat all our heads\n",
        "    output = torch.cat([h(x)[0] for h in self.heads], dim=-1)\n",
        "    output = self.projection(output)\n",
        "    return self.dropout(output)"
      ],
      "metadata": {
        "id": "9CGStKA19wOE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  # d_model --> number of neurons\n",
        "  def __init__(self, d_model, dropout=0.1):\n",
        "    super(FeedForward, self).__init__()\n",
        "    self.linear_1 = nn.Linear(d_model, 6*d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear_2 = nn.Linear(6*d_model, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear_1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear_2(x)\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "do-ZdI0shxau"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self, d_model, epsilon=1e-5):\n",
        "    super(LayerNormalization, self).__init__()\n",
        "    self.gamma = nn.Parameter(torch.ones(d_model))\n",
        "    self.beta = nn.Parameter(torch.zeros(d_model))\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True) # x is Pytorch Tensor so can call mean method straight\n",
        "    std = x.std(dim=-1, keepdim=True) # Standard Deviation\n",
        "    x = (x - mean) / (std + self.epsilon)\n",
        "    self.gamma * x * self.beta\n",
        "    return x"
      ],
      "metadata": {
        "id": "nRDMxEaYn9HE"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, d_model, n_head, dropout=0.1):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    head_size = n_embeddings // n_head\n",
        "    self.multi_head_attention = MultiHeadAttention(n_head, head_size, dropout)\n",
        "    self.feed_forward = FeedForward(d_model, dropout)\n",
        "    self.layer_normalization_1 = LayerNormalization(d_model)\n",
        "    self.layer_normalization_2 = LayerNormalization(d_model)\n",
        "    self.dropout_1 = nn.Dropout(dropout)\n",
        "    self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "  # Residual connection\n",
        "  def forward(self, x):\n",
        "    x_2 = self.layer_normalization_1(x)\n",
        "    x_2 = self.multi_head_attention(x_2)\n",
        "    x = x + x_2\n",
        "    x_2 = self.layer_normalization_2(x)\n",
        "    x_2 = self.feed_forward(x_2)\n",
        "    x = x + x_2\n",
        "    return x"
      ],
      "metadata": {
        "id": "95uR802go6MC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HYPERPARAMETERS\n",
        "\n",
        "Change these variables to change the total number of parameters"
      ],
      "metadata": {
        "id": "ahZ2G5PdsSEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "batch_size = 32\n",
        "block_size = 32\n",
        "max_n_iters = 30000\n",
        "evaluation_interval = 100\n",
        "evaluation_iterations = 200\n",
        "learning_rate = 5e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = \"mps\" --> for mac computers (arm64)\n",
        "\n",
        "# Parameters:\n",
        "n_embeddings = 64\n",
        "n_head = 4\n",
        "n_layers = 4\n",
        "dropout = 0.1"
      ],
      "metadata": {
        "id": "8lVb2RupsAWA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT Model"
      ],
      "metadata": {
        "id": "FI2SitZltFLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniFakeGPT(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embeddings)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embeddings)\n",
        "    self.transformer_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(n_embeddings, n_head, dropout) for i in range(n_layers)]\n",
        "    )\n",
        "    self.layer_normalization_forward = nn.LayerNorm(n_embeddings) # Using pytorch implementation instead of ours\n",
        "    self.linear_mapping_head = nn.Linear(n_embeddings, vocab_size) # linear mapping to attention head\n",
        "\n",
        "  def forward(self, index, targets=None): # Targets are labels, desired outputs\n",
        "    B, T = index.shape # Batch and Transformer blocks\n",
        "    token_embedding = self.token_embedding_table(index)\n",
        "    positional_embedding = self.position_embedding_table(torch.arange(T, device=device)) # Unique position for each individual input\n",
        "    x = token_embedding + positional_embedding\n",
        "    x = self.transformer_blocks(x)\n",
        "    x = self.layer_normalization_forward(x)\n",
        "    logits = self.linear_mapping_head(x) # predictions\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape # dimensions of output based on batches, input size\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets) # Cross Entropy as loss function\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, index, max_tokens): # max num of token to generate based on input\n",
        "    for i in range(max_tokens): # generate tokens until max_tokens is reached\n",
        "      index_state = index[:, -block_size:]\n",
        "      logits, loss = self(index_state) # forward pass\n",
        "      logits = logits[:, -1, :] # Focus on last timestep in the sequence\n",
        "      probabilities = F.softmax(logits, dim=-1) # distribution: probability of next token\n",
        "      index_next = torch.multinomial(probabilities, num_samples=1)\n",
        "      index = torch.cat((index, index_next), dim=1)\n",
        "    return index"
      ],
      "metadata": {
        "id": "fH8djB5stEK5"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MiniFakeGPT()\n",
        "m = model.to(device)"
      ],
      "metadata": {
        "id": "vSCsKZgYucYx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of parameters in Millions order"
      ],
      "metadata": {
        "id": "6JarQPauH3iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(p.numel() for p in model.parameters()) / 1e6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9hM04vAG2uh",
        "outputId": "74ac15f0-b544-49bb-b6ba-a4accc5d8d2a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.281066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "BgZWuYZhI1Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # Not to calculate gradients for optimization purposes\n",
        "def estimate_loss():\n",
        "  output = {}\n",
        "  model.eval()\n",
        "\n",
        "  for split in ['train', 'eval']:\n",
        "    losses = torch.zeros(evaluation_iterations)\n",
        "    for i in range(evaluation_iterations):\n",
        "      x, y = get_batch_data(split)\n",
        "      logits, loss = model(x, y)\n",
        "      losses[i] = loss.item()\n",
        "    output[split] = losses.mean()\n",
        "  model.train()\n",
        "  return output"
      ],
      "metadata": {
        "id": "ayDgg4L0HyTx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "nswfZqyOKAYZ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_n_iters):\n",
        "  if iter % evaluation_interval == 0 or iter == max_n_iters - 1:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step: {iter} - training loss: {losses['train']:.4f} - validation loss: {losses['eval']:.4f}\")\n",
        "\n",
        "  x, y = get_batch_data('train')\n",
        "  logits, loss = model(x, y) # forward pass\n",
        "  optimizer.zero_grad(set_to_none=True) # Updating the gradients in order to avoid gradient accumulation\n",
        "  loss.backward() # backward propagation for updating the weights\n",
        "  optimizer.step() # next step of learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GKpVonm4KKFA",
        "outputId": "36a29872-8c99-442f-ecf7-f6e2088d6ba9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-fb9a74b27d1d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_n_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluation_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_n_iters\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"step: {iter} - training loss: {losses['train']:.4f} - validation loss: {losses['eval']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-bf7b6dbbbaec>\u001b[0m in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-0eab15f1ba4b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, index, targets)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpositional_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Unique position for each individual input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositional_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_normalization_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_mapping_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-8d3cdb8a413e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_normalization_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_head_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_normalization_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-123f467ded9a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Concat all our heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-123f467ded9a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Concat all our heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-62afbed836a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_char = torch.zeros((1, 1), dtype=torch.long, device = device)"
      ],
      "metadata": {
        "id": "h9zu3OKoLYJM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_text = decode(m.generate(input_char, max_tokens=2000)[0].tolist())"
      ],
      "metadata": {
        "id": "2e2IRm4AWD7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_text)"
      ],
      "metadata": {
        "id": "er-xRC14Wrvp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}